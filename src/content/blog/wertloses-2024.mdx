---
title: "Wertloses 2024"
description: Wie die Informationen des Internets im letzten Jahr ihren Wert verloren haben.
pubDate: 2024-03-19T16:07:53.000Z
slug: wertloses-2024
draft: true
---

import Marginnote from "../../components/Marginnote.astro";
import Sidenote from "../../components/Sidenote.astro"
import Newthought from "../../components/Newthought.astro";

<blockquote class="epilogue">

</blockquote>

Ein "Hack" hat vergangene Woche meine Aufmerksamkeit auf sich gezogen: Um den Wahrheitsgehalt der Antworten zu erhöhen, soll man seinen Google-Suchen "`before:2023`" voranstellen. Laut Logik des unbekannten Urhebers filtert diese Einschränkung KI-generierte Inhalte aus den Ergebnissen.<br />Diese Inhalte überfluteten seit Mitte 2023 das Netz, seien Suchmaschinen optimiert, aber hätten den Wahrheitsgehalt, den man eben von *Large-Language-Models*<Sidenote> zu den bekanntesten gehören OpenAI's ChatGPT, Google's Bard, Facebook's LLaMA und das der französichen Firma <a rel="noopener" target="_blank" href="https://mistral.ai/">Mistral</a></Sidenote> erwarten kann: *Meistens zufällig richtig, andernfalls überzeugend, aber falsch.*

Antworten dieser Qualität würde ein durchschnittlich sorgfältiger Mensch - zumindest, wenn es wichtig ist - nachprüfen wollen, wodurch die Antwort wertlos wird. Information, die genauso gut erfunden wie korrekt sein kann, hat denselben Nutzen, wie keine Information.

Raten kann ich selbst und es mir dann auch noch schönrationalisieren, das kann ich noch viel besser. Dass ich meine eigene Fehlbarkeit seit letztem Jahr durch die Fehlbarkeit einer Maschine ersetzen kann, mag zwar eindrucksvoll sein, aber hilfreich ist es - zumindest unter diesem Gesichtspunkt - nicht.

Lange galt: Für kreatives Schreiben ChatGPT, aber wenn es um Fakten geht, dann doch lieber googeln. Was aber, wenn Google's Suchergebnisse alle von ChatGPT geschrieben worden sind?

Warum also stopfen wir das Internet mit diesen sinnlosen Informationen voll? Man muss die Antwort in der Struktur der Anreize des Internets suchen. Die verschiebt sich schon seit Längerem, 
aber durch die Veröffentlichungen diverser potenter künstlicher Intelligenzen wurde aus der gemächlichen Kontinentalverschiebung ein reißender Murenabgang.

Noch vor zehn Jahren waren die Motivationen aller Beteiligten mehr oder weniger auf ein gemeinsames Ziel ausgerichtet: Der Nutzer wollte die besten Informationen zu seiner Suchanfrage,
die Suchmaschine wollte sich durch Lieferung des besten Ergebnisses als bestes verfügbares Produkt profilieren und die Personen,
die die Inhalte ins Netz stellten waren in Folge dessen auch motiviert, die besten Inhalte zu erstellen.

<figure class="fullwidth"><img src="/img/trappedInPhone.webp" /></figure>

<Newthought>Was folgte war</Newthought> die Epiphanie der Entscheidungsträger im *Tal der Silikone*, dass die "besten" Inhalte ein geduldiger Begriff ist.
Sie verabschiedeten sich von dem unschulig naiven Axiom, dass dies immer die Art von Inhalt sein müsse, die dem Nutzer die akkurateste, verlässlichste Annäherung zur Wahrheit erlaubt,
sondern auch die sein kann, die ihn schockiert, aufwühlt, ihn in seiner Meinung bestätigt. Es sollte ein Inhalt sein, die er mit seinen Freunden teilt und zu
denen er einen toxischen Kommentar hinterlässt, während er versucht sich im Wartezimmer seines Urologen von den Gedanken an die bevorstehende Prostatauntersuchung abzulenken.

In einem solchen Ökosystem, in dem der Wille des Nutzers seinen Emotionen und niederen Instinkten untergeordnet wird und die Metriken des Internetkonsums zum Selbstzweck
werden haben die *Large Language Models* leichtes Spiel. Die können wesentlich besser mit den Konzepten der *SEO*<Sidenote>Search Engine Optimization, dt.: Suchmaschinenoptimierung</Sidenote>,
des User Engagements<Sidenote>Wie oft Nutzer Knöpfchen drücken, die mit dem Inhalt in Verbindung stehen.</Sidenote>
und der *Dwell Time*<Sidenote>Wie lange Nutzer auf der Seite verweilen.</Sidenote>
umgehen können, als mit dem Konzept der Wahrheit.<br />Letzteres ist in keinem Umfang Teil ihrer Wirklichkeit.

Denen, die also ihre Inhalte für Suchmaschinen optimieren wollen, ist durch diese neuen Errungenschaften also wesentlich mehr geholfen,
als jenen, die tugendhaftes Wahrheitsstreben verfolgen. Es scheinen sich alle - bis auf den Nutzer, der in diesem Spiel der Kräfte (gegenwärtig)
kaum mehr Einfluss hat, als ein Stück Treibholz auf den Strom eines Flusses - einig zu sein, dass automatisch generierter Nonsens, Expertise und gewissenhafter Recherche vorzuziehen ist,
solange er uns effektiv genug an unsere glühenden Rechtecke bindet.

<Newthought>Und dann</Newthought> haben wir uns alle TikTok installiert...

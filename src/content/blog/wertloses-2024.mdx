---
title: Wertloses 2024
description:
  Wie die Informationen des Internets im letzten Jahr ihren Wert verloren haben.
pubDate: 2024-03-19T16:07:53.000Z
slug: wertloses-2024
---

import Marginnote from "../../components/Marginnote.astro";
import Sidenote from "../../components/Sidenote.astro";
import Newthought from "../../components/Newthought.astro";

Ein "Hack" hat vergangene Woche meine Aufmerksamkeit auf sich gezogen: Um den
Wahrheitsgehalt der Antworten zu erhöhen, soll man seinen Google-Suchen
"`before:2023`" voranstellen. Laut Logik des unbekannten Urhebers filtert diese
Einschränkung KI-generierte Inhalte aus den Ergebnissen.<br />Diese Inhalte
überfluteten seit Mitte 2023 das Netz, seien Suchmaschinen optimiert, aber
hätten den Wahrheitsgehalt, den man eben von _Large-Language-Models_<Sidenote>
zu den bekanntesten gehören OpenAI's ChatGPT, Google's Bard, Facebook's LLaMA
und das der französichen Firma

<a rel="noopener" target="_blank" href="https://mistral.ai/">Mistral</a></Sidenote>
erwarten kann: _Meistens zufällig richtig, andernfalls überzeugend, aber
falsch._

Antworten dieser Qualität würde ein durchschnittlich sorgfältiger Mensch -
zumindest, wenn es wichtig ist - nachprüfen wollen, wodurch die Antwort wertlos
wird. Information, die genauso gut erfunden wie korrekt sein kann, hat denselben
Nutzen, wie keine Information.

Raten kann ich selbst und es mir dann auch noch schön zurechtrationalisieren,
das kann ich noch viel besser. Dass ich meine eigene Fehlbarkeit seit letztem
Jahr durch die Fehlbarkeit einer Maschine ersetzen kann, mag zwar eindrucksvoll
sein, aber hilfreich ist es - zumindest unter diesem Gesichtspunkt - nicht.

Lange galt: Für kreatives Schreiben ChatGPT, aber wenn es um Fakten geht, dann
doch lieber googeln. Was aber, wenn Google's Suchergebnisse alle von ChatGPT
geschrieben worden sind?

Warum also stopfen wir das Internet mit diesen sinnlosen Informationen voll? Man
muss die Antwort in der Struktur der Anreize des Internets suchen. Die
verschiebt sich schon seit Längerem, aber durch die Veröffentlichungen diverser
potenter künstlicher Intelligenzen wurde aus der gemächlichen
Kontinentalverschiebung ein reißender Murenabgang.

Noch vor zehn Jahren waren die Motivationen aller Beteiligten mehr oder weniger
auf ein gemeinsames Ziel ausgerichtet: Der Nutzer wollte die besten
Informationen zu seiner Suchanfrage, die Suchmaschine wollte sich durch
Lieferung des besten Ergebnisses als bestes verfügbares Produkt profilieren und
die Personen, die die Inhalte ins Netz stellten, waren infolgedessen auch
motiviert, die besten Inhalte zu erstellen.

<figure class="fullwidth">
  <img src="/img/trappedInPhone.webp" />
</figure>

<Newthought>Was folgte war</Newthought> die Epiphanie der Entscheidungsträger im
*Tal der Silikone*, dass die "besten" Inhalte ein geduldiger Begriff ist. Sie verabschiedeten
sich von dem unschuldig naiven Axiom, dass dies immer die Art von Inhalt sein müsse,
die dem Nutzer die akkurateste, verlässlichste Annäherung zur Wahrheit erlaubt, sondern
auch die sein kann, die ihn schockiert, aufwühlt, ihn in seiner Meinung bestätigt.
Es sollte ein Inhalt sein, die er mit seinen Freunden teilt und zu denen er einen
toxischen Kommentar hinterlässt, während er versucht, sich im Wartezimmer seines
Urologen von den Gedanken an die bevorstehende Prostatauntersuchung abzulenken.

In einem solchen Ökosystem, in dem der Wille des Nutzers seinen Emotionen und
niederen Instinkten untergeordnet wird und die Metriken des Internetkonsums zum
Selbstzweck werden, haben die _Large Language Models_ leichtes Spiel. Die können
wesentlich besser mit den Konzepten der _SEO_<Sidenote>Search Engine
Optimization, dt.: Suchmaschinenoptimierung</Sidenote>, des
_User-Engagements_<Sidenote>Wie oft Nutzer Knöpfchen drücken, die mit dem Inhalt
in Verbindung stehen.</Sidenote> und der _Dwell Time_<Sidenote>Wie lange Nutzer
auf der Seite verweilen.</Sidenote> umgehen können, als mit dem Konzept der
Wahrheit.<br />Letzteres ist in keinem Umfang Teil ihrer Wirklichkeit.

Denen, die also ihre Inhalte für Suchmaschinen optimieren wollen, ist durch
diese neuen Errungenschaften also wesentlich mehr geholfen, als jenen, die
tugendhaftes Wahrheitsstreben verfolgen. Alle (außer der Nutzer, der in diesem
Spiel der Kräfte keinen Einfluss mehr hat) einig zu sein: Automatisch
generierter Nonsens ist Expertise und gewissenhafter Recherche vorzuziehen,
solange er uns effektiv genug an unsere glühenden Rechtecke bindet.
